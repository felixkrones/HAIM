{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db715328",
   "metadata": {},
   "source": [
    "# HAIM test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7411736",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ccbd38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e8088c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape haim_mimiciv_key_ids: (8688, 3)\n",
      "Shape mimic_cxr_metadata: (377110, 16)\n",
      "Shape core: (2004607, 27)\n",
      "pickle files: 8688\n",
      "Shape haim_mimiciv_key_ids_filtered: (6148, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/wolf6245/envs/miniconda3/envs/haim/lib/python3.6/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/data/wolf6245/envs/miniconda3/envs/haim/lib/python3.6/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape core_filtered: (31381, 27)\n",
      "Shape mimic_cxr_metadata_filtered: (62590, 16)\n",
      "Shape mimic_cxr_metadata_filtered_filtered: (45882, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8688/8688 [06:58<00:00, 20.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pickle files with hadm_ids not in filter: 2540 of 8688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load filter data\n",
    "df_filter = pd.read_parquet(\"/data/wolf6245/src/mm_study/data/f_modelling/03_model_input/data-2024-12-19-01-23-23/(3) Chronic ischaemic heart disease/y_fusion_label_not_gt.parquet\")\n",
    "df_folds = pd.read_pickle(\"/data/wolf6245/src/mm_study/data/f_modelling/03_model_input/data-2024-12-19-01-23-23/(3) Chronic ischaemic heart disease/train_test_vali_folds_fusion_label.pkl\")\n",
    "subject_ids_to_use = [int(i) for i in df_filter['subject_id'].unique()]\n",
    "hadm_ids_to_use = [int(i) for i in df_filter['hadm_id'].unique()]\n",
    "\n",
    "# Load data\n",
    "haim_mimiciv_key_ids = pd.read_csv(\"/data/wolf6245/src/HAIM/data/haim_mimiciv/haim_mimiciv_key_ids.csv\")\n",
    "mimic_cxr_metadata = pd.read_csv(\"/data/wolf6245/src/HAIM/data/haim_mimiciv/mimic-cxr-2.0.0-metadata.csv\")\n",
    "core = pd.read_csv(\"/data/wolf6245/src/HAIM/data/haim_mimiciv/core/core.csv\")\n",
    "pickle_aux = pd.read_pickle(\"/data/wolf6245/src/HAIM/data/haim_mimiciv/pickle/00000000.pkl\")\n",
    "pickle_files = os.listdir(\"/data/wolf6245/src/HAIM/data/haim_mimiciv/pickle/\")\n",
    "\n",
    "# Shapes\n",
    "print(f\"Shape haim_mimiciv_key_ids: {haim_mimiciv_key_ids.shape}\")\n",
    "print(f\"Shape mimic_cxr_metadata: {mimic_cxr_metadata.shape}\")\n",
    "print(f\"Shape core: {core.shape}\")\n",
    "print(f\"pickle files: {len(pickle_files)}\")\n",
    "\n",
    "# Filter\n",
    "haim_mimiciv_key_ids_filtered = haim_mimiciv_key_ids[haim_mimiciv_key_ids['hadm_id'].astype(int).isin(hadm_ids_to_use)]\n",
    "print(f\"Shape haim_mimiciv_key_ids_filtered: {haim_mimiciv_key_ids_filtered.shape}\")\n",
    "core_filtered = core[core['hadm_id'].astype(int).isin(hadm_ids_to_use)]\n",
    "print(f\"Shape core_filtered: {core_filtered.shape}\")\n",
    "mimic_cxr_metadata_filtered = mimic_cxr_metadata[mimic_cxr_metadata['subject_id'].astype(int).isin(subject_ids_to_use)]\n",
    "print(f\"Shape mimic_cxr_metadata_filtered: {mimic_cxr_metadata_filtered.shape}\")\n",
    "\n",
    "# Filter cxr\n",
    "core_filtered['dischtime'] = pd.to_datetime(core_filtered['dischtime'])\n",
    "mimic_cxr_metadata_filtered['cxrtime'] = pd.to_datetime(mimic_cxr_metadata_filtered['cxrtime'])\n",
    "max_dischtime = core_filtered.copy().groupby('subject_id')['dischtime'].max().reset_index()\n",
    "max_dischtime.rename(columns={'dischtime': 'max_dischtime'}, inplace=True)\n",
    "merged = mimic_cxr_metadata_filtered.copy().merge(max_dischtime, on='subject_id', how='left')\n",
    "mimic_cxr_metadata_filtered_filtered = merged.copy()[merged['cxrtime'] <= merged['max_dischtime']].drop(columns=['max_dischtime'])\n",
    "print(f\"Shape mimic_cxr_metadata_filtered_filtered: {mimic_cxr_metadata_filtered_filtered.shape}\")\n",
    "\n",
    "# Get all hadm_ids\n",
    "files_to_remove = []\n",
    "for pickle_file in tqdm(pickle_files[:]):\n",
    "    pickle_file_path = os.path.join(\"/data/wolf6245/src/HAIM/data/haim_mimiciv/pickle/\", pickle_file)\n",
    "    pickle_df = pd.read_pickle(pickle_file_path)\n",
    "    hadm_ids_aux = [int(i) for i in pickle_df.admissions.hadm_id.unique()]\n",
    "    subject_ids_aux = [int(i) for i in pickle_df.admissions.subject_id.unique()]\n",
    "    if any([hadm_id not in hadm_ids_to_use for hadm_id in hadm_ids_aux]):\n",
    "            files_to_remove.append(pickle_file)\n",
    "print(f\"Number of pickle files with hadm_ids not in filter: {len(files_to_remove)} of {len(pickle_files)}\")\n",
    "\n",
    "if False:\n",
    "    # Save files back\n",
    "    haim_mimiciv_key_ids_filtered.to_csv(\"/data/wolf6245/src/HAIM/data/haim_mimiciv/haim_mimiciv_key_ids.csv\", index=False)\n",
    "    mimic_cxr_metadata_filtered_filtered.to_csv(\"/data/wolf6245/src/HAIM/data/haim_mimiciv/mimic-cxr-2.0.0-metadata.csv\", index=False)\n",
    "    core_filtered.to_csv(\"/data/wolf6245/src/HAIM/data/haim_mimiciv/core/core.csv\", index=False)\n",
    "\n",
    "    # Delete files in files_to_remove\n",
    "    for file in tqdm(files_to_remove, desc=\"Deleting files\"):\n",
    "        file_path = os.path.join(\"/data/wolf6245/src/HAIM/data/haim_mimiciv/pickle/\", file)\n",
    "        os.remove(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9035f675",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
